---
layout: post
title: Atlas of AI - Kate Crawford
subtitle: Power, Politics, and the Planetary Costs of Artificial Intelligence
categories: reading
date: 2021-10-26

---

### Intro

- **Central question**: How is intelligence “made,” and what traps can that create?
    - Warning of Clever Hans parable
    - Shift in AI from symbolic to machine learning techniques
    
    > In contrast, in this book I argue that AI is neither *artificial* nor *intelligent*. Rather, artificial intelligence is both embodied and material, made from natural resources, fuel, human labor, infrastructures, logistics, histories, and classifications.
    > 
    - AI serves dominant forces , registry of power → fundamentally political
- AI as an atlas
    
    > We need a theory of AI that accounts for the states and corporations that drive and dominate it, the extractive mining that leaves an imprint on the planet, the mass capture of data, and the profoundly unequal and increasingly exploitative labor practices that sustain it.
    > 
- Colonizing impulse and centralized power of AI “determines how the world is measured and defined while simultaneously denying that this is an inherently political activity.”
- This book frames AI as an *extractive industry*

### 1. Earth

**Mining for AI**

- Clayton Valley = source of mining for SI
- Lithium — batteries
- 17 rare earth elements (mining = dirty, polluting, all the things)

> From the perspective of deep time, we are extracting Earth’s geological history to serve a split second of contemporary technological time..
> 
- Latex — initially harvested from trees, driven to extinction
- Huge electrical energy needs to power servers and data centers; draw water away from communities and habitats to cool them

### AI as a megamachine

> Artificial intelligence is another kind of megamachine, a set of technological approaches that depend on industrial infrastructures, supply chains, and human labor that stretch around the globe but are kept opaque.
> 

## 2. Labor

- Amazon's human-robotic distribution system warehouses = key to understand trade-offs of automated efficiency → "consider how labor, capital, and time are entwined in AI systems"
    - How is work shifting with increased surveillance, algorithmic assessment, modulation of time?
    - How will humans be increasingly treated like robots, and what does this mean for the role of labor?
    - *Lineage of mechanized factory → model valuing increased conformity, standardization, and interoperability for products, processes, and humans*
- Oversight in modern workplace often → surveillance tech
- Under-recognized fact = number of unpaid workers required to build, maintain, test AI systems (Mechanical Turks)
- Controlling time ⇒ controlling bodies
    - Segmenting tasks into smaller and smaller pieces to be optimized and automated
    - Easier to surveil with time-tracking tools
    - Term "sabotage" in French coined by French anarchist Émile Pouget = "go slow"
- Problematic language of master and slave terminology throughout machine learning, tech in general

## 3. Data

- Mugshots make up huge dataset training AI for facial recognition… questionable morality
- Just as with extraction of materials, extraction of data reveals power structures
- Training data forms a “brittle ground truth”
    - No “neutral ground” of language
- Explosion of social media to be used as training data for facial recognition, image classification (often aided by low-wage workers)

> Data, in the twenty-first century, became whatever could be captured.
> 
- Now operates as a form of capital
- Ethics kept at about arm’s length— traditionally no human subjects in CS, machine learning

## 4. Classification

> The politics of classification is a core practice in artificial intelligence. The practices of classification inform how machine intelligence is recognized and produced from university labs to the tech industry.
> 
- Leads to bias, discriminatory results— circular logic

> The word “category” comes from the Ancient Greek katēgoríā, formed from two roots: kata (against) and agoreuo (speaking in public).
> 
- Enforces classification of race and gender and sexuality

> Making these choices about which information feeds AI systems to produce new classifications is a powerful moment of decision making: but who gets to choose and on what basis? The problem for computer science is that justice in AI systems will never be something that can be coded or computed.
> 

## 5. Affect

> By looking at the history of how *computer-based emotion detection* came to be, we can understand how its methods have raised both ethical concerns and scientific doubts.
> 
- In reality: no evidence  that you csb predict emotion from someone’s face!
- Idea of automatic affect recognition = compelling to military, intelligence and security agencies
- *Interpretation* of facial expressions highly dependent on social and cultural factors

> Recognition might be the wrong framework entirely when thinking about emotions because recognition assumes that emotional categories are givens, rather than emergent and relational.
> 

### 6. State

- DARPA → “The military priorities of command and control, automation, and surveillance profoundly shaped what AI was to become.”
- No national system: “AI systems operate within a complex interwoven network of multinational and multilateral tools, infrastructures, and labor.”
- Dual use of AI for civilian (commercial) and military (security) uses → close collab and funding
    - Ex. Project Maven
    - Outsourcing functions of state to tech sector (ex. Palantir, Vigilant)

## Conclusion

> AI is born from salt lakes in Bolivia and mines in Congo, constructed from crowdworker-labeled datasets that seek to classify human actions, emotions, and identities. It is used to navigate drones over Yemen, direct immigration police in the United States, and modulate credit scores of human value and risk across the world. A wide-angle, multiscalar perspective on AI is needed to contend with these overlapping regimes.
> 
- Search for a self-regulating, ethical system
